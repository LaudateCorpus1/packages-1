{
  "name": "bionode-waterwheel",
  "version": "0.4.0",
  "description": "Streaming workflow engine for bionformatics pipelines",
  "main": "index.js",
  "scripts": {
    "test": "mocha test/**/*.spec.js",
    "coverage": "istanbul cover _mocha --report lcovonly -- -R spec && rm -rf ./coverage",
    "book-build": "gitbook build",
    "book-serve": "gitbook serve"
  },
  "repository": {
    "user": "bionode",
    "repo": "bionode-waterwheel",
    "host": "github.com",
    "branch": "master",
    "apiHost": "api.github.com",
    "tarball_url": "https://api.github.com/repos/bionode/bionode-waterwheel/tarball/master",
    "clone_url": "https://github.com/bionode/bionode-waterwheel",
    "https_url": "https://github.com/bionode/bionode-waterwheel",
    "travis_url": "https://travis-ci.org/bionode/bionode-waterwheel",
    "zip_url": "https://github.com/bionode/bionode-waterwheel/archive/master.zip",
    "api_url": "https://api.github.com/repos/bionode/bionode-waterwheel"
  },
  "keywords": [
    "bionode",
    "pipeline",
    "workflow",
    "parallel",
    "streams",
    "streaming",
    "ngs",
    "bioinformatics",
    "computational",
    "biology"
  ],
  "author": {
    "name": "Julian Mazzitelli",
    "email": "mazzitelli.julian@gmail.com"
  },
  "license": "MIT",
  "homepage": "https://github.com/bionode/bionode-waterwheel#readme",
  "devDependencies": {
    "bionode-ncbi": "^1.6.1",
    "cdir": "^0.1.2",
    "chai": "^3.5.0",
    "chai-as-promised": "^5.3.0",
    "codecov": "^1.0.1",
    "duplexify": "^3.4.3",
    "gitbook-cli": "^2.3.0",
    "into-stream": "^2.0.1",
    "isstream": "^0.1.2",
    "istanbul": "^0.4.4",
    "mocha": "^2.5.3",
    "redux-logger": "^2.6.1",
    "request": "^2.72.0",
    "split": "^1.0.0",
    "stream-assert": "^2.0.3",
    "through2": "^2.0.1"
  },
  "dependencies": {
    "async-done": "^1.2.2",
    "bluebird": "^3.4.1",
    "chalk": "^1.1.3",
    "checksum": "^0.1.1",
    "duplexify": "^3.4.5",
    "eventemitter2": "^2.0.1",
    "fs-extra": "^0.30.0",
    "fs-symlink": "^1.2.1",
    "globby": "^5.0.0",
    "graph.js": "^1.20.10",
    "json-stable-stringify": "^1.0.1",
    "lodash": "^4.14.0",
    "minimatch": "^3.0.2",
    "mkdirp": "^0.5.1",
    "multimatch": "^2.1.0",
    "now-and-later": "^1.0.0",
    "once": "^1.3.3",
    "readable-stream": "^2.1.4",
    "redux": "^3.5.2",
    "redux-saga": "^0.11.0",
    "redux-thunk": "^2.1.0",
    "stream-from-promise": "^1.0.0"
  },
  "gitHead": "1b48215937bf1bad3402ac6501d1c6d48a691d4c",
  "_npmVersion": "3.10.3",
  "_nodeVersion": "6.5.0",
  "dist": {
    "shasum": "283e80e38f938e236d81819259ca3f729dda7c33",
    "tarball": "http://registry.npmjs.org/bionode-waterwheel/-/bionode-waterwheel-0.4.0.tgz"
  },
  "deprecated": "This module has been renamed to bionode-watermill",
  "versions": [
    {
      "number": "0.1.0",
      "date": "2016-06-24T06:04:12.641Z"
    },
    {
      "number": "0.1.1",
      "date": "2016-06-24T07:32:06.831Z"
    },
    {
      "number": "0.2.0",
      "date": "2016-07-16T15:38:35.844Z"
    },
    {
      "number": "0.3.0",
      "date": "2016-08-21T14:09:08.932Z"
    },
    {
      "number": "0.4.0",
      "date": "2016-10-26T01:37:47.844Z"
    }
  ],
  "created": "2016-06-24T06:04:12.641Z",
  "modified": "2016-10-26T03:03:53.808Z",
  "lastPublisher": {
    "name": "thejmazz",
    "email": "mazzitelli.julian@gmail.com"
  },
  "owners": [
    {
      "name": "thejmazz",
      "email": "mazzitelli.julian@gmail.com"
    }
  ],
  "readme": "# bionode-watermill\n\n[![npm version](https://badge.fury.io/js/bionode-waterwheel.svg)](https://badge.fury.io/js/bionode-waterwheel) [![node](https://img.shields.io/badge/node-v6.x-blue.svg)]() [![Build Status](https://travis-ci.org/bionode/bionode-watermill.svg?branch=master)](https://travis-ci.org/bionode/bionode-waterwheel)  [![codecov.io](https://codecov.io/github/bionode/bionode-watermill/coverage.svg?branch=master)](https://codecov.io/github/bionode/bionode-waterwheel?branch=master)\n\n*Watermill: A Streaming Workflow Engine*\n\n[![NPM](https://nodei.co/npm/bionode-waterwheel.png?downloads=true&stars=true)](https://nodei.co/npm/bionode-waterwheel/)\n\nWatermill lets you *orchestrate* **tasks** using operators like **join**, **junction**, and **fork**. Each task has a [lifecycle](https://thejmazz.gitbooks.io/bionode-watermill/content/TaskLifecycle.html) where\n\n1. Input [glob patterns](https://github.com/isaacs/node-glob) are resolved to absolute file paths (e.g. `*.bam` to `reads.bam`)\n2. The **operation** is ran, passed resolved input, params, and other props\n3. The operation completes.\n4. Output glob patterns are resolved to absolute file paths.\n5. Validators are ran over the output. Check for non-null files, can pass in custom validators.\n6. Post-validations are ran. Add task and output to DAG.\n\n## What is a task?\n\nA `task` is the fundamental unit pipelines are built with. For more details, see [Task](https://thejmazz.gitbooks.io/bionode-watermill/content/Task.html). At a glance, a task is created by passing in **props** and an **operationCreator**, which will later be called with the resolved input. Consider this task which takes a \"lowercase\" file and creates an \"uppercase\" one:\n\n```javascript\nconst uppercase = task({\n  input: '*.lowercase',\n  output: '*.uppercase'\n}, function(resolvedProps) {\n  const input = resolvedProps.input\n  \n  return fs.createReadStream(input)\n  \t.pipe(through function(chunk, enc, next) {\n      next(null, chunk.toString().toUpperCase())\n  \t})\n    .pipe(fs.createWriteStream(input.replace(/lowercase$/, 'uppercase')))\n})\n```\n\nA \"task declaration\" like above will not immediately run the task. Instead, the task declaration returns an \"invocable task\" that can either be called directly or used with an orchestration operator. Tasks can also be created to **run shell programs**:\n\n```javascript\nconst fastqDump = task({\n  input: '**/*.sra',\n  output: [1, 2].map(n => `*_${n}.fastq.gz`),\n  name: 'fastq-dump **/*.sra'\n}, ({ input }) => `fastq-dump --split-files --skip-technical --gzip ${input}` )\n```\n\n## What are orchestrators?\n\nOrchestrators are functions which can take tasks as params in order to let you compose your pipeline from a high level view. This **separates task order from task declaration**. For more details, see [Orchestration](https://thejmazz.gitbooks.io/bionode-watermill/content/Orchestration.html). At a glance, here is a complex usage of `join`, `junction`, and `fork`:\n\n```javascript\nconst pipeline = join(\n  junction(\n    join(getReference, bwaIndex),\n    join(getSamples, fastqDump)\n  ),\n  trim, mergeTrimEnds,\n  decompressReference, // only b/c mpileup did not like fna.gz\n  join(\n    fork(filterKMC, filterKHMER),\n    alignAndSort, samtoolsIndex, mpileupAndCall // 2 instances each of these\n  )\n)\n```\n\n## Examples\n\n- [Toy pipeline with shell/node](https://github.com/bionode/bionode-watermill/blob/master/examples/pids/pipeline.js)\n- [Simple capitalize task](https://github.com/bionode/bionode-watermill/blob/master/examples/capitalize/capitalize.js)\n- [Simple SNP calling](https://github.com/bionode/bionode-watermill/blob/master/examples/variant-calling-simple/pipeline.js)\n- [SNP calling with filtering and fork](https://github.com/bionode/bionode-watermill/blob/master/examples/variant-calling-filtered/pipeline.js)\n\n## Who is this tool for?\n\nWaterwheel is for **programmers** who desire an efficient and easy-to-write methodology for developing complex and dynamic data pipelines, while handling parallelization as much as possible. Waterwheel is an npm module, and is accessible by anyone willing to learn a little JavaScript. This is in contrast to other tools which develop their own DSL (domain specific language), which is not useful outside the tool. By leveraging the npm ecosystem and JavaScript on the client, Waterwheel can be built upon for inclusion on web apis, modern web applications, as well as native applications through [Electron](http://electron.atom.io/). Look forward to seeing Galaxy-like applications backed by a completely configurable Node API.\n\nWaterwheel is for **biologists** who understand it is important to experiment with sample data, parameter values, and tools. Compared to other workflow systems, the ease of swapping around parameters and tools is much improved, allowing you to iteratively compare results and construct more confident inferences. Consider the ability to construct your own [Teaser](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-015-0803-1) for *your data* with a *simple syntax*, and getting utmost performance out of the box.\n"
}