{
  "name": "audio-timeline",
  "version": "1.3.0",
  "description": "Observ object for arranging, trimming and adjusting multiple audio clips on a timeline using Web Audio.",
  "main": "index.js",
  "scripts": {
    "test": "standard",
    "playback-example": "electron-spawn examples/playback.js",
    "render-example": "electron-spawn examples/render.js"
  },
  "repository": {
    "user": "mmckegg",
    "repo": "audio-timeline",
    "host": "github.com",
    "branch": "master",
    "apiHost": "api.github.com",
    "tarball_url": "https://api.github.com/repos/mmckegg/audio-timeline/tarball/master",
    "clone_url": "https://github.com/mmckegg/audio-timeline",
    "https_url": "https://github.com/mmckegg/audio-timeline",
    "travis_url": "https://travis-ci.org/mmckegg/audio-timeline",
    "zip_url": "https://github.com/mmckegg/audio-timeline/archive/master.zip",
    "api_url": "https://api.github.com/repos/mmckegg/audio-timeline"
  },
  "keywords": [
    "timeline",
    "edit",
    "wave",
    "editor",
    "clips",
    "trim",
    "audacity",
    "frp",
    "observ",
    "audio-slot"
  ],
  "author": {
    "name": "Matt McKegg"
  },
  "license": "MIT",
  "homepage": "https://github.com/mmckegg/audio-timeline",
  "devDependencies": {
    "electron-prebuilt": "^0.37.6",
    "electron-spawn": "^3.0.0",
    "standard": "^5.0.2",
    "wav": "^1.0.0"
  },
  "dependencies": {
    "audio-buffer-range-decoder": "~2.0.0",
    "geval": "^2.1.1",
    "observ": "^0.2.0",
    "observ-default": "^1.0.0",
    "observ-node-array": "^1.12.0",
    "observ-struct": "^6.0.0"
  },
  "gitHead": "506379c87d2fc87a9e0511a68c736272d4a36d63",
  "_npmVersion": "3.10.3",
  "_nodeVersion": "6.3.1",
  "dist": {
    "shasum": "f2746829bfd8ed4e3a065e47e8e0c380780cbf17",
    "tarball": "http://registry.npmjs.org/audio-timeline/-/audio-timeline-1.3.0.tgz"
  },
  "versions": [
    {
      "number": "1.0.0",
      "date": "2015-08-18T05:28:46.537Z"
    },
    {
      "number": "1.0.1",
      "date": "2015-08-18T05:33:53.857Z"
    },
    {
      "number": "1.0.2",
      "date": "2015-08-19T13:03:50.381Z"
    },
    {
      "number": "1.1.0",
      "date": "2015-08-28T06:52:44.901Z"
    },
    {
      "number": "1.1.1",
      "date": "2015-08-28T16:40:54.829Z"
    },
    {
      "number": "1.2.0",
      "date": "2015-10-09T08:19:14.181Z"
    },
    {
      "number": "1.2.1",
      "date": "2016-07-28T02:54:43.412Z"
    },
    {
      "number": "1.3.0",
      "date": "2016-08-01T04:12:55.703Z"
    }
  ],
  "created": "2015-08-18T05:28:46.537Z",
  "modified": "2016-08-01T04:12:55.703Z",
  "lastPublisher": {
    "name": "mmckegg",
    "email": "matt@wetsand.co.nz"
  },
  "owners": [
    {
      "name": "mmckegg",
      "email": "matt@wetsand.co.nz"
    }
  ],
  "readme": "audio-timeline\n===\n\n[Observ](https://github.com/raynos/observ-struct) object for arranging, trimming and adjusting multiple audio clips on a timeline using [Web Audio](https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API).\n\n[![NPM](https://nodei.co/npm/audio-timeline.png)](https://nodei.co/npm/audio-timeline/)\n\n## Example\n\n```js\nvar Timeline = require('audio-timeline')\nvar audioContext = new window.AudioContext() // Web Audio\n\nvar context = {\n  audio: audioContext,\n  output: audioContext.destination,\n  fs: require('fs'),\n  cwd: __dirname,\n  nodes: {\n    clip: require('audio-timeline/clip')\n  }\n}\n\nvar timeline = Timeline(context)\ntimeline.set({\n  primary: [\n    { node: 'clip',\n      src: 'audio/raw.wav',\n      startOffset: 0,\n      duration: 25\n    },\n    { node: 'clip',\n      src: 'audio/raw.wav',\n      startOffset: 500,\n      duration: 30\n    },\n    { node: 'clip',\n      src: 'audio/raw.wav',\n      startOffset: 1000,\n      duration: 16\n    }\n  ]\n})\n```\n### Playback\n\n```js\nvar startAt = audioContext.currentTime + 0.1\nvar startOffset = 0\nvar duration = 71\n\ntimeline.start(startAt, startOffset, duration)\n```\n\n### Render to disk\n\n```js\nvar RenderStream = require('audio-timeline/render-stream')\nvar WaveFileWriter = require('wav').FileWriter\n\nvar startOffset = 0\nvar duration = 71\nvar bitDepth = 16\n\nvar stream = RenderStream(timeline, startOffset, duration, bitDepth)\n\nstream.pipe(WaveFileWriter('output.wav', {\n  bitDepth: bitDepth,\n  sampleRate: audioContext.sampleRate,\n  channels: 2\n})).on('finish', function() {\n  console.log('done')\n})\n\nstream.progress(function(value) {\n  console.log(Math.round(value*100))\n})\n```"
}